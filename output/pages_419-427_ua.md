Таблиця 12.1: Порівняння різних методів, що використовуються для обмеження ймовірностей хвостів

| Результат    | Сценарій                                    | Сила     |
|--------------|----------------------------------------------|----------|
| Чебишева     | Будь-яка випадкова величина                 | Слабка    |
| Маркова      | Невід'ємна випадкова величина               | Слабка    |
| Гоффдінга    | Сума незалежних обмежених випадкових величин| Сильна   |
| Чернова      | Сума незалежних змінних Бернуллі            | Сильна   |

Ця нерівність справджується для будь-якого невід'ємного значення t. Отже, щоб знайти найжорсткішу границю, потрібно визначити значення t, яке мінімізує праву частину наведеного вище рівняння. Оптимальне значення t = t* можна показати як:

$$
t^* = \frac{40}{\sum_{i=1}^n (u_i - l_i)^2} .
$$

(12.17)

Підставляючи значення t = t* у рівняння 12.16, можна отримати бажаний результат. Границю нижнього хвоста можна вивести, застосувавши вищезазначені кроки до $P(E[X] - X > \theta)$ замість $P(X - E[X] > \theta)$.

Таким чином, різні нерівності можуть застосовуватися до сценаріїв різної загальності, а також можуть мати різні рівні сили. Ці різні сценарії проілюстровано в таблиці 12.1.

## 12.2.2 Структури синопсисів для сценарію масивного домену

Як зазначалося у вступі, багато потокових додатків містять дискретні атрибути, домен яких складається з великої кількості різних значень. Класичним прикладом є значення IP-адреси в мережевому потоці або адреси електронної пошти в потоці електронної пошти. Такі сценарії є більш поширеними в потоках даних, просто тому, що величезна кількість елементів даних у потоці часто асоціюється з дискретними ідентифікаторами різних типів. Адреси електронної пошти та IP-адреси є прикладами таких ідентифікаторів. Потокові об'єкти часто асоціюються з парами ідентифікаторів. Наприклад, кожен елемент потоку електронної пошти може мати як відправника, так і одержувача. В деяких додатках може бути бажано зберігати статистику з використанням парних ідентифікаторів, і тому парна комбінація розглядається як єдиний інтегрований атрибут. Домен можливих значень може бути досить великим. Наприклад, для додатку електронної пошти з понад сотнею мільйонів різних відправників та одержувачів кількість можливих парних комбінацій становить $10^{16}$. У таких випадках навіть зберігання простої зведеної статистики, такої як належність до множини, підрахунок частих елементів та підрахунок різних елементів, стає більш складним з точки зору обмежень на простір.

Якби кількість різних елементів була нев
### 12.2.2.1 Фільтр Блума

Фільтри Блума призначені для запитів про належність дискретних елементів до множини. Запит про належність до множини має такий вигляд:

Чи траплявся певний елемент у потоці даних?

Фільтри Блума забезпечують спосіб підтримки синопсису потоку, щоб на це запитання можна було відповісти з імовірнісною межею точності. Одна властивість цієї структури даних полягає в тому, що можливі хибно позитивні результати, але не можливі хибно негативні. Іншими словами, якщо фільтр Блума повідомляє, що елемент не належить до потоку, то це завжди буде так. Фільтри Блума називаються "фільтрами", оскільки їх можна використовувати для прийняття важливих рішень про відбір у потоці в режимі реального часу. Це пов'язано з тим, що знання про належність елемента до множини елементів потоку відіграє важливу роль у рішеннях про фільтрацію, таких як видалення дублікатів. Це буде розглянуто більш детально пізніше. Спочатку буде розглянуто простий випадок запитів про належність до потоку.

Фільтр Блума - це двійковий бітовий масив довжиною $m$. Таким чином, вимога до пам'яті для фільтра Блума становить $m/8$ байтів. Елементи бітового масиву індексуються, починаючи з 0 і закінчуючи $(m - 1)$. Отже, діапазон індексів - $[0, 1, 2, ... m - 1]$. З фільтром Блума пов'язано набір з $w$ незалежних хеш-функцій, позначених як $h_1(\cdot) \ldots h_w(\cdot)$. Аргументом кожної з цих хеш-функцій є елемент потоку даних. Хеш-функція відображає рівномірно випадковим чином на ціле число в діапазоні $[0 \ldots m - 1]$.

Розглянемо потік дискретних елементів. Ці дискретні елементи можуть бути адресами електронної пошти (окремо або парами відправник-одержувач), IP-адресами або іншим набором дискретних значень, взятих з величезної області можливих значень. Біти у фільтрі Блума використовуються для відстеження унікальних значень, що зустрічаються. Хеш-функції використовуються для відображення елементів потоку на біти у фільтрі Блума. У наступному обговоренні буде припущено, що структура даних фільтра Блума позначається як $B$.

Фільтр Блума будується з потоку $S$ значень наступним чином. Всі біти у фільтрі Блума ініціалізуються нулями. Для кожного вхідного елемента потоку $x$ до нього застосовуються функції $h_1(x) \ldots h_w(x)$. Для кожного $i \in [1 \ldots w]$ елемент $h_i(x)$ у фільтрі Блума встановлюється в 1. У багатьох випадках значення деяких з цих бітів може вже бути 
Алгоритм BloomConstruct(Потік: $S$, Розмір: $m$, Кількість хеш-функцій: $w$)
початок
  Ініціалізувати всі елементи в бітовому масиві $B$ розміру $m$ до 0;
  повторювати
    Отримати наступний елемент потоку $x \in S$;
    для $i = 1$ до $w$ зробити
      Оновити $h_i(x)$-й елемент у бітовому масиві $B$ до 1;
    до кінця потоку $S$;
  повернути $B$;
кінець

[Рисунок 12.2: Оновлення блум-фільтра, сторінка 400]

неможливі з блум-фільтром. З іншого боку, якщо всі записи $h_1(y) \ldots h_w(y)$ у бітовому масиві мають значення 1, то повідомляється, що $y$ траплявся у потоці даних. Це можна ефективно перевірити, застосувавши логічну операцію "AND" до всіх бітових записів, що відповідають індексам $h_1(y) \ldots h_w(y)$ у бітовому масиві. Загальна процедура перевірки членства ілюструється на рис. 12.3. Бінарний результат для проблеми прийняття рішення щодо перевірки членства відстежується змінною $BooleanFlag$. Цей бінарний прапорець повідомляється в кінці процедури.

Підхід блум-фільтра може призводити до хибних позитивних результатів, але не до хибних негативних. Хибний позитивний результат виникає, якщо всі $w$ різних елементів масиву блум-фільтра $h_i(y)$ для $i = 1 \ldots w$ були встановлені на 1 деяким сторонніми елементом, відмінним від $y$. Це прямий результат колізій. Зі збільшенням кількості елементів у потоці даних, всі елементи у блум-фільтрі врешті-решт встановлюються на 1. У такому випадку всі запити на перевірку членства дадуть позитивну відповідь. Звичайно, це не є корисним застосуванням блум-фільтра. Тому доцільно обмежити ймовірність хибного позитивного результату в залежності від розміру фільтра та кількості різних елементів у потоці даних.

Лема 12.2.2 Розглянемо блум-фільтр $B$ з $m$ елементами та $w$ різними хеш-функціями. Нехай $n$ - кількість різних елементів у потоці $S$ на даний момент. Розглянемо елемент $y$, який ще не з'являвся у потоці. Тоді ймовірність $F$ того, що елемент $y$ буде повідомлений як хибний позитивний результат, задається наступним чином:

$$
F = \left[ 1 - \left( 1 - \frac{1}{m} \right)^{wn} \right]^w
$$

(12.18)
Алгоритм BloomQuery(Елемент: y, Фільтр Блума: B)
початок
  Ініціалізувати BooleanFlag = 1;
  для i = 1 до w зробити
    BooleanFlag = BooleanFlag AND h_i(y);
  повернути BooleanFlag;
кінець

[Рисунок 12.3: Перевірка членства за допомогою фільтра Блума, сторінка 401]

Доведення: Розглянемо конкретний біт, що відповідає елементу бітового масиву h_r(y) для деякого фіксованого значення індексу r ∈ {1...w}. Кожен елемент x ∈ S встановлює u різних бітів h_1(x)...h_u(x) в 1. Ймовірність того, що жоден з цих бітів не збігається з h_r(y), дається виразом (1 - 1/m)^u. Для n різних елементів потоку ця ймовірність дорівнює (1 - 1/m)^un. Отже, ймовірність того, що бітовий масив з індексом h_r(y) встановлено в 1 принаймні одним з n сторонніх елементів в S, дається виразом Q = 1 - (1 - 1/m)^un. Хибний позитивний результат виникає, коли всі індекси бітового масиву h_r(y) (для різних значень r ∈ {1...w}) встановлені в 1. Ймовірність цього дорівнює F = Q^w. Результат випливає.

Хоча ймовірність хибного позитивного результату виражена вище через кількість різних елементів потоку, це тривіально справедливо для загальної кількості елементів потоку (включаючи повтори), як верхня межа.

Вираз у вищезгаданій лемі можна спростити, спостерігаючи, що (1 - 1/m)^m ≈ e^(-1), де e - основа натурального логарифму. Відповідно, вираз можна переписати наступним чином:
$$
F = (1 - e^{-u/m})^w.
$$
(12.19)

Занадто малі або занадто великі значення u призводять до поганої продуктивності. Значення u необхідно вибрати оптимально з точки зору m та n, щоб мінімізувати кількість хибних позитивних результатів. Кількість хибних позитивних результатів мінімізується, коли u = m * ln(2)/n. Підставляючи це значення в рівняння 12.19, можна показати, що ймовірність хибних позитивних результатів для оптимальної кількості хеш-функцій дорівнює:
$$
F = 2^{-m \cdot ln(2)/n}.
$$
(12.20)

Вираз вище можна записати виключно як вираз m/n. Отже, для фіксованого значення ймовірності хибного позитивного результату F, довжина фільтра Блума повинна бути пропорційною кількості різних елементів n у потоці даних. Більше того, константа пропорційності для конкретної ймовірності хибного позитивного результату F може бути показана як
$$
\frac{m}{n} = \left(\frac{\ln(1/F)}{(\ln(2))^2}\right).
$$
Хоча це може не здаватися значним стисненням, слід зазначити, що фільтри Блума використовують елементарні біти для відстеження членства довільних елементів, таких як рядки. Крім того, завдяки бітовим операціям, які можна реалізувати дуже ефективно з низькорівневими реалізаціями, загальний підхід зазвичай дуже ефективний.

Слід пам'ятати, що значення n наперед невідоме для багатьох застосувань. Тому одна стратегія полягає у використанні каскаду фільтрів Блума для геометрично зростаючих значень u та використанні логічного AND результату запиту на членство над різними фільтрами Блума. Це практичний підхід, який забезпечує більш стабільну продуктивність протягом усього життєвого циклу потоку даних.

Фільтр Блума називається "фільтром", оскільки його часто використовують для прийняття рішень про виключення елементів з потоку даних, коли вони відповідають умові членства.
Наприклад, якщо потрібно відфільтрувати всі дублікати з потоку даних, фільтр Блума є ефективною стратегією. Іншою стратегією є фільтрування заборонених елементів з універсуму значень, наприклад, набору спам-адрес електронної пошти в потоці електронної пошти. У такому випадку фільтр Блума потрібно попередньо сконструювати зі спам-адресами електронної пошти.

Існує багато варіацій базової стратегії фільтра Блума, які забезпечують різні можливості та компроміси:

1. Фільтр Блума можна використовувати для приблизної оцінки кількості унікальних елементів у потоці даних. Якщо $m_0 < m$ - кількість бітів зі значенням 0 у фільтрі Блума, то кількість унікальних елементів $n$ можна оцінити наступним чином (див. Вправу 13):

$$
n \approx \frac{m}{w} \cdot \ln(m/m_0)
$$

(12.21)

Точність цієї оцінки різко знижується, коли фільтр Блума заповнюється. Коли $m_0 = 0$, значення $n$ оцінюється як $\infty$, і тому оцінка практично безкорисна.

2. Фільтр Блума можна використовувати для оцінки розміру перетину та об'єднання множин, що відповідають різним потокам, створивши один фільтр Блума для кожного потоку. Щоб визначити розмір об'єднання, визначається побітове ОР двох фільтрів. Можна показати, що побітове ОР фільтрів точно відповідає представленню фільтра Блума об'єднання двох множин. Потім застосовується формула рівняння 12.21. Однак такий підхід не можна використовувати для визначення розміру перетину. Хоча перетин двох множин можна приблизно оцінити, використовуючи операцію побітового AND над двома фільтрами, результуючі позиції бітів у фільтрі не будуть такими ж, як ті, що отримані шляхом безпосереднього конструювання фільтра на перетині. Результуючий фільтр може містити хибні негативи, і тому такий підхід є втратним. Щоб оцінити розмір перетину, спочатку можна оцінити розмір об'єднання, а потім використати наступне просте співвідношення для множин:

$$
|S_1 \cap S_2| = |S_1| + |S_2| - |S_1 \cup S_2|
$$

(12.22)

3. Фільтр Блума в першу чергу призначений для запитів на членство, і не є найбільш ефективною з точки зору використання пам'яті структурою даних, коли використовується виключно для підрахунку унікальних елементів. У наступному розділі буде розглянуто ефективний з точки зору використання пам'яті метод, відомий як алгоритм Флажоле-Мартіна.

4. Фільтр Блума може дозволити обмежене (одноразове) відстеження видалень, встановлюючи відповідні бітові елементи в нуль, коли елемент видаляється. У такому випадку також можливі хибні негативи.

5. Можна розробити варіанти фільтра Блума, в яких $u$ хеш-функцій можуть відображатися на окремі бітові масиви. Подальшим узагальненням цього принципу є відстеження підрахунків елементів, а не просто бінарних бітових значень, щоб забезпечити більш багаті запити. Це узагальнення, яке розглядається в наступному розділі, також називається нарисом count-min.

Фільтри Блума широко використовуються в багатьох потокових налаштуваннях у текстовій області.
#### 12.2.2.2 Скетч Count-Min

Хоча фільтр Блума ефективний для запитів на перевірку членства, він не призначений для методів, які вимагають *підсумків на основі підрахунку*. Це тому, що фільтр Блума відстежує лише бінарні значення. Скетч count-min призначений для вирішення таких запитів і інтуїтивно пов'язаний з фільтром Блума. Скетч count-min складається з набору $w$ різних *числових масивів*, кожен з яких має довжину $m$. Таким чином, вимога до пам'яті для скетчу count-min дорівнює $m \cdot w$ комірок, що містять числові значення. Елементи кожного з $w$ числових масивів індексуються, починаючи з 0, що відповідає діапазону індексів $\{0...m - 1\}$. Скетч count-min також можна розглядати як $w \times m$-вимірний масив комірок.

Кожен з $w$ числових масивів відповідає хеш-функції. $i$-й числовий масив відповідає $i$-й хеш-функції $h_i(\cdot)$. Хеш-функції мають такі властивості:

1. $i$-та хеш-функція $h_i(\cdot)$ відображає елемент потоку на ціле число в діапазоні $[0...m - 1]$. Це відображення також можна розглядати як одне із значень індексу в $i$-му числовому масиві.

2. $w$ хеш-функцій $h_1(\cdot)...h_w(\cdot)$ повністю незалежні одна від одної, але *попарно незалежні* для різних аргументів. Іншими словами, для будь-яких двох значень $x_1$ та $x_2$, $h_i(x_1)$ та $h_i(x_2)$ є незалежними.

Вимога *попарної незалежності* є слабшою, ніж вимога повної незалежності. Це зручна властивість скетчу count-min, оскільки зазвичай легше побудувати попарно незалежні хеш-функції, ніж повністю незалежні.

Процедура оновлення скетчу виглядає так. Всі $m \cdot w$ записів у скетчі count-min ініціалізуються нулями. Для кожного вхідного елемента потоку $x$ до нього застосовуються функції $h_1(x)...h_w(x)$. Для $i$-го масиву елемент $h_i(x)$ збільшується на 1. Таким чином, якщо скетч count-min $\text{CM}$ візуалізувати як 2-вимірний $w \times m$ числовий масив, то елемент $(i, h_i(x))$ збільшується на 1. Зверніть увагу, що значення $h_i(x)$ відображається на ціле число в діапазоні $[0, m - 1]$. Це також діапазон індексів кожного числового масиву. Ілюстрація скетчу count-min та відповідного процесу оновлення наведена на Рис. 12.4. Псевдокод для загального процесу оновлення проілюстровано на Рис. 12.5. У псевдокоді потік позначається як $S$, а структура даних скетчу count-min позначається як $\text{CM}$. Вхідними даними для алгоритму є потік $S$ та два параметри $(w, m)$, що визначають розмір 2-вимірного масиву для скетчу count-min. 2-вимірний масив $\text{CM}$ розміром $w \times m$ ініціалізується з усіма значеннями, встановленими на 0. Для кожного вхідного елемента потоку підраховуються всі
[ілюстрація, сторінка 403]
Алгоритм CountMinConstruct(Потік: $S$, Ширина: $w$, Висота: $m$)
початок
    Ініціалізувати всі елементи масиву $w \times m$ $CM$ до 0;
    повторювати
        Отримати наступний елемент потоку $x \in S$;
        для $i = 1$ до $w$ зробити
            Збільшити $(i, h_i(x))$-й елемент в $CM$ на 1;
    до кінця потоку $S$;
    повернути $CM$;
кінець

Алгоритм CountMinQuery(Елемент: $y$, Ескіз Count-min: $CM$)
```
початок
    Ініціалізувати $Оцінка = \infty$;
    для $i = 1$ до $w$ зробити
        $Оцінка = \min(Оцінка, V_i(y))$;
    { $V_i(y)$ - це підрахунок $(i, h_i(y))$-го елемента в $CM$ }
    повернути $Оцінка$;
кінець
```

[Рисунок 12.5: Оновлення ескізу count-min, сторінка 404]

[Рисунок 12.6: Запити частоти для ескізу count-min, сторінка 404]

комірки $(i, h_i(x))$ оновлюються для $i \in \{1 \ldots w\}$. У псевдокоді опис, результуючий ескіз $CM$ повертається після обробки всіх елементів потоку. На практиці, ескіз count-min може використовуватися в будь-який момент під час проходження потоку $S$. Як і у випадку з фільтром Блума, можливо, що кілька елементів потоку відображаються на одну й ту саму комірку в ескізі count-min. Тому різні елементи потоку будуть збільшувати одну й ту саму комірку, і результуючі підрахунки комірок завжди будуть завищеними оцінками одного або більше підрахунків елементів потоку.

Ескіз count-min може використовуватися для багатьох різних запитів. Найпростіший запит - визначити частоту елемента $y$. Перший крок - обчислити хеш-функції $h_1(y) \ldots h_w(y)$. Для кожного числового масиву в $CM$, значення $V_i(y)$ $(i, h_i(y))$-го елемента масиву вибирається. Значення $V_i(y)$ є завищеною оцінкою справжньої частоти $y$ через потенційні колізії. Тому найбільш точна можлива оцінка може бути отримана за допомогою мінімального значення $min(V_i(y))$ над різними хеш-функціями. Загальна процедура для оцінки частоти проілюстрована на Рис. 12.6.

Ескіз count-min призводить до завищення оцінок частоти через колізії ненегативних частот різних елементів потоку. Тому корисно визначити верхню межу якості оцінки.

Лема 12.2.3 Нехай $E(y)$ - оцінка частоти елемента $y$, використовуючи ескіз count-min розміру $w \times m$. Нехай $n_f$ - загальні частоти всіх елементів, отриманих до цього часу, а $G(y)$ - справжня частота елемента $y$. Тоді, з ймовірністю принаймні $1 - e^{-w}$, верхня межа оцінки $E(y)$ є такою:
$$
E(y) \leq G(y) + \frac{n_f \cdot e}{m}.
$$
Тут $e$ представляє основу натурального логарифму. (12.23)
Доведення: Очікувана кількість хибних елементів, хешованих у комірки, що належать елементу y, становить близько $3 \cdot n_f/m$, якщо всі хибні елементи хешуються рівномірно випадково у різні комірки. Цей результат використовує попарну незалежність хеш-функцій, оскільки він спирається на той факт, що відображення y у комірку не впливає на розподіл іншого хибного елемента у його комірках. Ймовірність того, що кількість хибних елементів перевищить $n_f \cdot \varepsilon/m$ у будь-якій з w комірок, що належать y, задається не більше ніж $e^{-1}$ за нерівністю Маркова. Для того, щоб $E(y)$ перевищила верхню межу рівняння 12.23, це порушення має повторюватися для всіх w комірок, у які відображається y. Отже, ймовірність порушення рівняння 12.23 становить $e^{-w}$. Звідси випливає результат.

У багатьох випадках бажано безпосередньо контролювати рівень помилки $\varepsilon$ та ймовірність помилки $\delta$. Встановивши $m = e/\varepsilon$ та $w = ln(1/\delta)$, можна обмежити помилку з заданою користувачем толерантністю $n_f \cdot \varepsilon$ та ймовірністю принаймні $1 - \delta$. Два природні узагальнення точкового запиту можна реалізувати наступним чином:

1. Якщо елементи потоку мають довільні позитивні частоти, пов'язані з ними, єдина зміна, необхідна для операції оновлення, де підрахунки збільшуються на відповідну частоту. Обмеження частоти ідентичне рівнянню 12.23, де $n_f$ представляє суму частот елементів потоку.

2. Якщо елементи потоку мають позитивні або негативні частоти, пов'язані з ними, то необхідна додаткова зміна в процедурі запиту. У цьому випадку повідомляється медіана підрахунків. Відповідне обмеження помилки рівняння 12.23 тепер потрібно змінити. З ймовірністю принаймні $1 - e^{-w/4}$ оцінена частота $E(y)$ елемента y лежить у наступних діапазонах:

$$
G(y) - \frac{3n_f \cdot \varepsilon}{m} \leq E(y) \leq G(y) + \frac{3n_f \cdot \varepsilon}{m}.
$$

У цьому випадку $n_f$ представляє суму абсолютних частот вхідних елементів у потоці даних. Межі в цьому випадку набагато слабкіші, ніж для невід'ємних елементів.

Корисним застосуванням є визначення скалярного добутку частот значень дискретних атрибутів у двох потоках даних. Це має корисне застосування для оцінки розміру з'єднання на масивному домені атрибутів у двох потоках даних. Скалярний добуток між частотами елементів у парі невід'ємних потоків даних можна оцінити, спочатку побудувавши представлення count-min sketch для кожного з двох потоків даних в окремій структурі даних count-min $w \times m$. Для обох ескізів використовуються ті самі хеш-функції. Обчислюється скалярний добуток їхніх відповідних масивів count-min для кожної хеш-функції. Мінімальне значення скалярного добутку над w різними масивами повідомляється як оцінка. Як і в попередньому випадку, це є завищеною оцінкою, і верхня межа оцінки може бути отримана з ймовірністю принаймні $1 - e^{-w}$. Відповідна толерантність помилки для верхньої межі становить $n_{f1} \cdot n_{f2} \cdot \varepsilon/m$, де $n_{f1}$ та $n_{f2}$ є сумарними частотами елементів у кожному з двох потоків. Інші корисні запити з використанням count-min sketch включають визначення квантилів та частих елементів. Часті елементи також називаються важливими елементами. У бібліографічних примітках містяться посилання на різні запити та застосування, які можна вирішити за допомогою count-min sketch.
#### 12.2.2.3 Нарис AMS

Як обговорювалося на початку цього розділу, різні структури синопсису призначені для різних видів запитів. Хоча блум-фільтр та скетч count-min забезпечують хорошу оцінку різних запитів, деякі запити, такі як другі моменти, можуть бути краще вирішені за допомогою скетчу Алона-Матіаса-Сегеді (AMS). У скетчі AMS для кожного елемента потоку генерується випадкове бінарне значення з {-1, 1} шляхом застосування хеш-функції до елемента потоку. Вважається, що ці бінарні значення є 4-незалежними. Це означає, що якщо вибрати не більше чотирьох значень, згенерованих однією і тією ж хеш-функцією, вони будуть статистично незалежними одне від одного. Розробити 4-незалежну хеш-функцію простіше, ніж повністю незалежну хеш-функцію. Деталі 4-незалежних хеш-функцій можна знайти в бібліографічних нотатках.

Розглянемо потік, в якому i-й елемент потоку асоціюється з _агрегованою частотою_ $f_i$. Другий момент $F_2$ потоку даних для потоку з $n$ _різними елементами_ визначається наступним чином:

$$
F_2 = \sum_{i=1}^{n} f_i^2
$$

У сценарії масивного домену, де кількість різних елементів велика, це значення важко оцінити, оскільки підрахунок частот $f_i$ не можна підтримувати за допомогою масиву. Однак його можна ефективно оцінити за допомогою скетчу AMS. Як практичне застосування, другий момент дає оцінку розміру самоз'єднання потоку даних щодо атрибута масивного домену. Другий момент також можна розглядати як варіант індексу Джині, який вимірює рівень нахилу частоти для різних елементів у потоці даних. Коли нахил великий, значення $F_2$ велике і дуже близьке до його верхньої межі $(\sum_{i=1}^{n} f_i)^2$.

Скетч AMS містить $m$ різних компонентів скетчу, кожен з яких асоціюється з незалежною хеш-функцією. Кожна хеш-функція генерує відповідний компонент скетчу наступним чином. Для вхідного елемента потоку генерується випадкове бінарне значення з рівною ймовірністю для обох реалізацій. Це бінарне значення позначається як $r \in \{-1, 1\}$ і генерується за допомогою хеш-функції для цього компонента. Частота кожного вхідного елемента потоку множиться на $r$ і додається до відповідного компонента скетчу. Нехай $r_i \in \{-1, 1\}$ - випадкове значення, згенероване певною хеш-функцією для i-го різного елемента. Тоді відповідний компонент $Q$ скетчу для потоку з $n$ різними елементами з агрегованими частотами $f_1 \ldots f_n$ можна показати рівним наступному:

$$
Q = \sum_{i=1}^{n} f_i \cdot r_i
$$

Це співвідношення обумовлене інкрементним способом оновлення $Q$ кожного разу, коли надходить елемент потоку. Зверніть увагу, що значення $Q$ є випадковою величиною, яка залежить від того, як бінарні випадкові значення $r_1 \ldots r_n$ генеруються хеш-функцією. Значення $Q$ корисне для оцінки другого моменту.

##### Лема 12.2.2.4 Другий момент потоку даних можна оцінити за квадратом компонента скетчу AMS $Q$:

$$
F_2 = E[Q^2].
$$

_Доведення_: Легко побачити, що $Q^2 = \sum_{i=1}^{n} f_i^2 r_i^2 + 2 \sum_{i=1}^{n} \sum_{j=i+1}^{n} f_i \cdot f_j \cdot r_i \cdot r_j$. Для будь-якої пари хеш-значень $r_i, r_j$ маємо $r_i^2 = r_j^2 = 1$ і $E[r_i \cdot r_j] = E[r_i] \cdot E[r_j] = 0$. Останнє з
