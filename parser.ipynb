{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the 'env.txt' file by uploading a copy of your .env file, or make a new one with the below contents:\n",
    "```yaml\n",
    "\n",
    "# Anthropic\n",
    "ANTHROPIC_API_KEY=<YOUR ANTHROPIC API KEY>\n",
    "\n",
    "# OpenAI\n",
    "OPENAI_API_KEY=<YOUR ANTHROPIC API KEY>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('env.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_parser_system_prompt = '''\n",
    "\n",
    "You're a helpful assistant for blind students helping to read the texts with formulas from images.\n",
    "\n",
    "You read the text with formulas and mathematic symbols and convert it to markdown using LaTeX for them using syntax from examples below.\n",
    "\n",
    "User will send you the scanned pages of a book one by one, and you would respond with the markdown code. \n",
    "\n",
    "1. Don't include the header with the chapter title and footnotes in the content.\n",
    "2. Use markdown for titles, lists, tables, etc.\n",
    "3. Don't add anything, just respond with the parsed text. \n",
    "4. For illustrations, insert [illustration, page N], N is the page number (top right for even or left for odd). Don't try to parse the text on illustrations.\n",
    "5. Always use \"$\" notation for inline formulas, and \"$$\" for displayed formulas.\n",
    "6. Don't add anything outside of the triple backticks.\n",
    "\n",
    "Example of a LaTeX formula in Markdown:\n",
    "```\n",
    "Here is an inline formula: $E = mc^2$.\n",
    "\n",
    "And here is a displayed formula:\n",
    "$$\n",
    "E = mc^2\n",
    "$$\n",
    "\n",
    "```\n",
    "\n",
    "Example of markdown titles:\n",
    "```\n",
    "# Chapter 2\n",
    "# Data Preparation\n",
    "\n",
    "## 7.1 Introduction\n",
    "\n",
    "### 7.2.1 Representative-Based Algorithms\n",
    "\n",
    "#### 7.2.1.1 k-Modes Clustering\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_core langchain_openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Markdown to ./markdown/page_424.md\n",
      "Processed page 424\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import os\n",
    "import time\n",
    "\n",
    "# SETTINGS\n",
    "model = \"gpt-4-vision-preview\"\n",
    "max_tokens = 4096\n",
    "first_page = 424\n",
    "last_page = 424\n",
    "markdown_folder = './markdown'\n",
    "\n",
    "\n",
    "def process_page(image_url, markdown_folder, system_prompt=markdown_parser_system_prompt):\n",
    "    base_name = os.path.basename(image_url)\n",
    "    md_filename = os.path.splitext(base_name)[0] + '.md'\n",
    "    file_path = os.path.join(markdown_folder, md_filename)\n",
    "\n",
    "    def save_markdown(input_str, file_path):\n",
    "        if input_str.startswith('```') and input_str.endswith('```'):\n",
    "            content = input_str[3:-3]\n",
    "        else:\n",
    "            content = input_str\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "\n",
    "    chat = ChatOpenAI(model=model, max_tokens=max_tokens)\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"Please read the text on the image.\"},\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    output = chat.invoke(messages)\n",
    "\n",
    "    save_markdown(output.content, file_path)\n",
    "    print(f'Saved Markdown to {file_path}')\n",
    "\n",
    "\n",
    "for page in range(first_page, last_page + 1):\n",
    "    page_string = str(page).zfill(3)\n",
    "    image_url = f'https://translation-demo.s3.eu-central-1.amazonaws.com/images/page_{page_string}.jpeg'\n",
    "    process_page(image_url, markdown_folder)\n",
    "    print(f'Processed page {page}')\n",
    "    time.sleep(0.5)  # Wait 0.5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet langchain langchain_anthropic anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_system_prompt = '''\n",
    "\n",
    "You are a top-notch technical translator, specializing in translating scientific markdown files on COMPUTER SCIENCE. \n",
    "\n",
    "User will send you a file contents in English, and you will translate it to Ukrainian. For specific terms, refer to the dictionary below.\n",
    "\n",
    "1. Keep the meaning as close as pssible to original, remember that it is a technical document for data science specialists.\n",
    "2. You are NOT allowed to change the structure or formatting of the document.\n",
    "3. You are NOT allowed to change the Latex formulas.\n",
    "4. You respond in pure markdown format, without any additional content.\n",
    "5. Don't add anything, just translate the text.\n",
    "6. You allowed to use only common names for terms. If you don't find the term in the dictionary, keep it in English.\n",
    "\n",
    "<dictionary>\n",
    "{dictionary}\n",
    "</dictionary>\n",
    "\n",
    "'''\n",
    "\n",
    "dictionary = \"\\n\".join([\n",
    "    \"bloom filter - фільтр Блума\",\n",
    "    \"count–min sketch - скетч count–min\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved translation to ./markdown_ua/page_424_ua.md\n",
      "Processed page 424\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "model = 'claude-3-sonnet-20240229'\n",
    "max_tokens = 4096\n",
    "markdown_folder = './markdown'\n",
    "output_folder = './markdown_ua'\n",
    "first_page = 424\n",
    "last_page = 424\n",
    "\n",
    "def save_markdown(input_str, file_path):\n",
    "    if input_str.startswith('```markdown'):\n",
    "        content = input_str[len('```markdown'):].lstrip()\n",
    "    elif input_str.startswith('```'):\n",
    "        content = input_str[3:].lstrip()\n",
    "    else:\n",
    "        content = input_str\n",
    "\n",
    "    if content.endswith('```'):\n",
    "        content = content[:-3].rstrip()\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def translate_file(file_name, output_folder, system_prompt=translate_system_prompt):\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    llm = ChatAnthropic(temperature=0, model_name=model, max_tokens=max_tokens)\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    human_message = \"{text}\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", human_message)\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "\n",
    "    response = chain.invoke({\"dictionary\": dictionary,\"text\": text})\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(file_name))[0] + '_ua.md'\n",
    "    file_path = os.path.join(output_folder, base_name)\n",
    "    save_markdown(response.content, file_path)\n",
    "    print(f'Saved translation to {file_path}')\n",
    "    return text\n",
    "\n",
    "for page in range(first_page, last_page + 1):\n",
    "    page_string = str(page).zfill(3)\n",
    "    file_name = f'{markdown_folder}/page_{page_string}.md'\n",
    "    translate_file(file_name, output_folder)\n",
    "    print(f'Processed page {page}')\n",
    "    time.sleep(0.5)  # Wait 0.5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str=''''''\n",
    "\n",
    "if input_str.startswith('```markdown'):\n",
    "    content = input_str[len('```markdown'):].rstrip(' ').rstrip('\\n').rstrip('```').strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anton-zv152aIY",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
