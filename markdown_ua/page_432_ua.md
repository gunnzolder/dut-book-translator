Масив. Розгляньмо ситуацію, коли вже оброблено n елементів. Оскільки кожен сегмент містить w елементів, загалом було оброблено $r = O(n/w) = O(n \cdot \epsilon)$ сегментів. Це означає, що будь-який конкретний елемент був зменшений не більше, ніж $r = O(n \cdot \epsilon)$ разів. Отже, якщо до підрахунків елементів після обробки n елементів додати $\lfloor n \cdot \epsilon \rfloor$, то жоден підрахунок не буде недооцінений. Крім того, це добра переоцінка частоти, пропорційна заданій користувачем терпимості $\epsilon$. Якщо часті елементи будуть повідомлятися з використанням цієї переоцінки, це може призвести до деяких хибно позитивних результатів, але не буде хибно негативних.

За деяких припущень щодо рівномірності було показано, що алгоритм втратного підрахунку вимагає $O(1/\epsilon)$ простору.

Цей підхід можна узагальнити на випадок частих шаблонів шляхом групування декількох сегментів розміром $w = \lfloor 1/\epsilon \rfloor$. У цьому випадку підтримуються масиви, що містять підрахунки шаблонів (а не елементів). Однак, очевидно, що шаблони не можна ефективно генерувати з окремих транзакцій. Ідея полягає в тому, щоб згрупувати $\eta$ сегментів, які завантажуються в основну пам'ять. Значення $\eta$ визначається на основі доступної пам'яті. Коли $\eta$ сегментів завантажено, часті шаблони з (абсолютною) підтримкою принаймні $\eta$ визначаються за допомогою будь-якого алгоритму пошуку частих шаблонів, що базується на пам'яті. Спочатку всі старі підрахунки в масиві зменшуються на $\eta$, а потім підрахунки відповідних шаблонів з поточного сегмента додаються до масиву. Ті наборі елементів, підтримка яких дорівнює нулю або є негативною, видаляються з масиву. Протягом усього процесу обробки потоку довжиною n підрахунок будь-якого набору елементів зменшується не більше, ніж на $\lfloor \epsilon \cdot n \rfloor$. Отже, додавши $\lfloor \epsilon \cdot n \rfloor$ до всіх підрахунків масиву в кінці процесу, жоден підрахунок не буде недооцінений. Переоцінка така ж, як і в попередньому випадку. Таким чином, можна повідомляти про часті шаблони без хибно негативних результатів, а хибно позитивні результати регулюються заданою користувачем терпимістю $\epsilon$. Концептуально, основна відмінність цього алгоритму підрахунку частих наборів елементів від згаданого вище алгоритму підрахунку частих елементів полягає у використанні групування. Основна мета групування - зменшити кількість частих шаблонів, згенерованих на рівні підтримки $\eta$ під час застосування алгоритму пошуку частих шаблонів. Якщо не використовувати групування, то буде згенеровано велику кількість нерелевантних частих шаблонів на рівні абсолютної підтримки 1.

Основний недолік втратного підрахунку полягає в тому, що він не може адаптуватися до дрейфу концепції. У цьому сенсі резервне вибірка має ряд переваг над алгоритмом втратного підрахунку.

# 12.4 Кластеризація потоків даних

Проблема кластеризації особливо важлива в сценарії потоку даних через її здатність надавати компактний синопсис потоку даних. Кластеризація потоку даних часто може використовуватися як евристична заміна резервного вибірки, особливо якщо використовується детальна кластеризація. З цих причин кластеризація потоків часто використовується як попередник для інших застосувань, таких як класифікація потоків. Далі буде розглянуто кілька репрезентативних алгоритмів кластеризації потоків.

## 12.4.1 Алгоритм STREAM

Алгоритм STREAM базується на методології кластеризації k-медіан. Основна ідея полягає в розбитті потоку на менші сегменти, що вміщуються в пам'яті. Таким чином, вихідний потік даних $S$ ділиться на сегменти $S_1 \ldots S_r$. Кожен сегмент містить не більше $m$ точок даних. Значення $m$ фіксується на основі заданого бюджету пам'яті.

Оскільки кожен сегмент $S_i$ вміщується в основній пам'яті, до нього можна застосувати більш складний алгоритм кластеризації, не турбуючись про обмеження одного проходу. Можна використати різноманітні