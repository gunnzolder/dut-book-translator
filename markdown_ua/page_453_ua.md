Коефіцієнт Жаккара рідко використовується для текстового домену, але він дуже часто використовується для розріджених бінарних даних, а також для множин. Багато форм транзакційних даних та даних про ринкові кошики використовують коефіцієнт Жаккара. Слід зазначити, що транзакційні дані та дані про ринкові кошики мають багато спільного з текстом через їх розрідженість та невід'ємні характеристики. Більшість методів text mining, що обговорюються в цьому розділі, також можуть бути застосовані до цих доменів з незначними модифікаціями.

### 13.2.2 Спеціалізована попередня обробка для веб-документів

Веб-документи вимагають спеціалізованих методів попередньої обробки через деякі загальні властивості їх структури та багатство посилань всередині них. Два основні аспекти попередньої обробки веб-документів включають видалення певних частин документів (наприклад, тегів), які не є корисними, та використання фактичної структури документа. HTML-теги зазвичай видаляються більшістю методів попередньої обробки.

HTML-документи мають численні поля, такі як заголовок, метадані та тіло документа. Зазвичай, аналітичні алгоритми розглядають ці поля з різними рівнями важливості, тому вони мають різну вагу. Наприклад, заголовок документа вважається важливішим за тіло і має більшу вагу. Іншим прикладом є анкор-текст у веб-документах. Анкор-текст містить опис веб-сторінки, на яку вказує посилання. Через свій описовий характер він вважається важливим, але іноді не є релевантним до теми самої сторінки. Тому його часто видаляють з тексту документа. В деяких випадках, де це можливо, анкор-текст навіть може бути доданий до тексту документа, на який він вказує. Це пов'язано з тим, що анкор-текст часто є стислим описом документа, на який він вказує.

Веб-сторінка часто може бути організована у блоки контенту, які не пов'язані з основною темою сторінки. Типова веб-сторінка матиме багато нерелевантних блоків, таких як реклама, застереження чи повідомлення, які не дуже корисні для майнінгу. Було показано, що якість результатів майнінгу покращується, коли використовується лише текст у головному блоці. Однак, (автоматичне) визначення головних блоків з веб-колекцій масштабу веб є самою по собі задачею data mining, що представляє інтерес. Хоча розкласти веб-сторінку на блоки відносно легко, іноді важко ідентифікувати головний блок. Більшість автоматизованих методів для визначення головних блоків спираються на той факт, що певний сайт, як правило, використовує подібний макет для документів на цьому сайті. Тому, якщо доступна колекція документів з сайту, можуть бути використані два типи автоматизованих методів:

1. **Розмітка блоків як задача класифікації**: Ідея в цьому випадку полягає у створенні нового навчального набору даних, який витягує візуальні ознаки рендерингу для кожного блоку в навчальних даних за допомогою веб-браузерів, таких як Internet Explorer. Багато браузерів надають API, який можна використовувати для витягування координат кожного блоку. Головний блок потім вручну розмічається для деяких прикладів. Це призводить до створення навчального набору даних. Отриманий навчальний набір даних використовується для побудови моделі класифікації. Ця модель використовується для ідентифікації головного блоку в решті (нерозмічених) документів сайту.

2. **Підхід на основі порівняння дерев**: Більшість веб-сайтів генерують документи, використовуючи фіксований шаблон. Тому, якщо можна витягти шаблон, то головний блок можна ідентифікувати відносно легко. Першим кроком є витягування дерев тегів з HTML-сторінок. Вони представляють часті шаблони дерев на веб-сайті. Алгоритм порівняння дерев, обговорений у бібліографічному розділі, може бути використаний для визначення таких шаблонів з цих дерев тегів. Після того, як шаблони були знайдені, визначається, який блок є головним у витягнутому шаблоні. Багато периферійних блоків часто мають подібний вміст на різних сторінках і тому можуть бути виключені.