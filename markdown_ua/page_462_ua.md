Важливим припущенням у PLSA є те, що вибрані документи та слова є умовно незалежними після фіксації прихованої тематичної компоненти $G_m$. Іншими словами, припускається наступне:

$$
P(X_i, w_j | G_m) = P(X_i | G_m) \cdot P(w_j | G_m) \tag{13.7}
$$

Це означає, що спільну ймовірність $P(X_i, w_j)$ для вибору пари документ-слово можна виразити наступним чином:

$$
P(X_i, w_j) = \sum_{m=1}^k P(G_m) \cdot P(X_i, w_j | G_m) = \sum_{m=1}^k P(G_m) \cdot P(X_i | G_m) \cdot P(w_j | G_m) \tag{13.8}
$$

Важливо зазначити, що локальна незалежність між документами та словами в межах прихованої компоненти не означає глобальної незалежності між тією самою парою у всьому корпусі. Припущення про локальну незалежність корисне для виведення алгоритму EM.

У PLSA оцінюється апостеріорна ймовірність $P(G_m | X_i, w_j)$ прихованої компоненти, пов'язаної з певною парою документ-слово. Алгоритм EM починається з ініціалізації $P(G_m)$, $P(X_i | G_m)$ та $P(w_j | G_m)$ значеннями $1/k$, $1/n$ та $1/d$ відповідно. Тут $k$, $n$ та $d$ позначають кількість кластерів, кількість документів та кількість слів відповідно. Алгоритм ітеративно виконує наступні кроки E та M до збіжності:

1. (Крок E) Оцінити апостеріорну ймовірність $P(G_m | X_i, w_j)$ у термінах $P(G_m)$, $P(X_i | G_m)$ та $P(w_j | G_m)$.

2. (Крок M) Оцінити $P(G_m)$, $P(X_i | G_m)$ та $P(w_j | G_m)$ у термінах апостеріорної ймовірності $P(G_m | X_i, w_j)$ та спостережуваних даних про співіснування слів та документів за допомогою максимізації логарифмічної правдоподібності.

Ці кроки ітеративно повторюються до збіжності. Тепер залишається обговорити деталі кроку E та кроку M. Спочатку розглянемо крок E. Апостеріорну ймовірність, оцінену на кроці E, можна розгорнути за допомогою правила Байєса:

$$
P(G_m | X_i, w_j) = \frac{P(G_m) \cdot P(X_i, w_j | G_m)}{P(X_i, w_j)} \tag{13.9}
$$

Чисельник правої частини наведеного рівняння можна розгорнути за допомогою рівняння 13.7, а знаменник - за допомогою рівняння 13.8:

$$
P(G_m | X_i, w_j) = \frac{P(G_m) \cdot P(X_i | G_m) \cdot P(w_j | G_m)}{\sum_{r=1}^k P(G_r) \cdot P(X_i | G_r) \cdot P(w_j | G_r)} \tag{13.10}
$$

Це показує, що крок E можна реалізувати у термінах оцінених значень $P(G_m)$, $P(X_i | G_m)$ та $P(w_j | G_m)$.

Залишається показати, як ці значення можна оцінити за допомогою спостережуваних співіснувань слів та документів на кроці M. Апостеріорні ймовірності $P(G_m | X_i, w_j)$ можна розглядати як ваги, прикріплені до пар співіснування слів та документів для кожного аспекту $G_m$. Ці ваги можна використовувати для оцінки значень $P(G_m)$, $P(X_i | G_m)$ та $P(w_j | G_m)$ для кожного аспекту за допомогою максимізації функції логарифмічної правдоподібності. Деталі функції логарифмічної правдоподібності та диференціального обчислення, пов'язаного з процесом максимізації, тут не розглядатимуться. Натомість будуть представлені безпосередньо кінцеві оцінені значення. Нехай $f(X_i, w_j)$ позначає