досягається з оригінальним набором даних з високою ймовірністю. Границя Хоффдінга використовується для
оцінки цієї ймовірності, і тому проміжні кроки підходу розроблені з урахуванням цієї границі.
Ось чому такі дерева називаються деревами Хоффдінга.

Дерево Хоффдінга може бути побудоване поступово шляхом одночасного зростання дерева
з надходженням потоку. Важливим припущенням є те, що потік не еволюціонує, і
тому нещодавно прибулий набір точок можна розглядати як вибірку з повного потоку.
Вищі рівні дерева будуються на ранніх етапах потоку, коли зібрано достатньо
кортежів для кількісної оцінки точності відповідних критеріїв розбиття. Вузли
нижчого рівня будуються пізніше, оскільки статистику про вузли нижчого рівня можна
зібрати лише після побудови вузлів вищого рівня. Таким чином, послідовні рівні
дерева будуються, коли надходять нові приклади, і дерево продовжує рости. Ключовим
у алгоритмі дерева Хоффдінга є кількісна оцінка моменту, коли зібрано статистично достатню
кількість кортежів для виконання розбиття, щоб розбиття було приблизно таким самим, як і
при знанні повного потоку.

Те саме дерево рішень буде побудоване на поточній вибірці потоку та повному
потоці, якщо на кожному етапі використовуються ті самі розбиття. Отже, метою підходу
є забезпечення того, щоб розбиття на вибірці були ідентичними розбиттям на повному потоці. Для
зручності обговорення розглянемо випадок, коли кожен атрибут^6 є бінарним. У цьому випадку два алгоритми
створять точно таке саме дерево, якщо на кожному етапі буде вибрано той самий атрибут розбиття.
Атрибут розбиття вибирається за допомогою міри, такої як індекс Джині. Розгляньмо
конкретний вузол у дереві, побудованому на оригінальних даних, і той самий вузол, побудований
на вибірці даних. Яка ймовірність того, що для вибірки потоку буде вибрано той самий атрибут,
що й для повного потоку?

Розгляньмо найкращий і другий за якістю атрибути для розбиття, позначені як $i$ та $j$ відповідно,
у вибірці даних. Нехай $G_i$ та $G_i'$ - значення індексу Джині для атрибута розбиття $i$,
обчислені на повному потоці та вибірці даних відповідно. Оскільки атрибут $i$
був вибраний для розбиття у вибірці даних, очевидно, що $G_i' < G_j'$. Проблема полягає в тому,
що вибірка може спричинити помилку. Іншими словами, для оригінальних даних може бути так, що $G_j < G_i$.
Нехай різниця $G_j' - G_i'$ між $G_j'$ та $G_i'$ дорівнює $\epsilon > 0$. Якщо кількість
вибірок $n$ для оцінки розбиття достатньо велика, то можна показати з використанням
границі Хоффдінга, що небажаний випадок, коли $G_j < G_i$, не відбудеться з принаймні
заданою користувачем ймовірністю $1 - \delta$. Необхідне значення $n$ буде функцією $\epsilon$ та $\delta$. У
контексті потоків даних з безперервним накопиченням вибірок ключовим є очікування
достатньо великого розміру вибірки $n$ перед виконанням розбиття. У дереві Хоффдінга
границя Хоффдінга використовується для визначення значення $n$ у термінах $\epsilon$ та $\delta$ наступним чином:

$$
n = \frac{R^2 \cdot \ln(1/\delta)}{2 \epsilon^2}
\tag{12.32}
$$

Значення $R$ позначає діапазон критерію розбиття. Для індексу Джині значення $R$ дорівнює
1, а для критерію ентропії значення дорівнює $\log(k)$, де $k$ - кількість класів. Близькі
зв'язки в критерії розбиття відповідають малим значенням $\epsilon$. Згідно з рівнянням 12.32, такі зв'язки
призведуть до великих вимог до розміру вибірки, а отже, і до більшого часу очікування, поки
не можна буде достатньо впевнено виконати розбиття з наявною вибіркою потоку.

Підхід дерева Хоффдінга визначає, чи поточна різниця в індексі Джині
між найкращим і другим за якістю атрибутами розбиття є принаймні $\sqrt{\frac{R^2 \cdot \ln(1/\delta)}{2n}}$, щоб ініціювати
розбиття. Це забезпечує гарантію якості розбиття в конкретному вузлі. У деяких випадках,