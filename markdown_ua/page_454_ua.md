# 13.3 Спеціалізовані методи кластеризації для тексту

Більшість алгоритмів, обговорених у Розділі 6, можна розширити на текстові дані. Це тому, що векторне представлення тексту також є багатовимірною точкою даних. Обговорення в цьому розділі спочатку зосередиться на загальних модифікаціях багатовимірних алгоритмів кластеризації, а потім представить конкретні алгоритми в цих контекстах. Деякі методи кластеризації, обговорені в Розділі 6, використовуються частіше, ніж інші, в текстовій області. Алгоритми, які використовують невід'ємні, розріджені та високовимірні особливості текстової області, зазвичай кращі за ті, які цього не роблять. Багато алгоритмів кластеризації вимагають значних коригувань для вирішення особливої структури текстових даних. Далі необхідні модифікації деяких важливих алгоритмів будуть детально розглянуті.

## 13.3.1 Алгоритми на основі представників

Вони відповідають сімейству алгоритмів, таких як $k$-середніх, $k$-модів та $k$-медіанних алгоритмів. Серед них алгоритми $k$-середніх найчастіше використовуються для текстових даних. Для ефективного застосування цих алгоритмів до текстових даних потрібні дві основні модифікації.

1. Перша модифікація - це вибір функції подібності. Замість евклідової відстані використовується функція косинусної подібності.

2. Внесено зміни до обчислення центроїду кластера. Не всі слова в центроїді зберігаються. Слова з низькою частотою в кластері проектуються. Зазвичай у кожному центроїді зберігається максимум 200-400 слів. Це також називається дайджестом кластера, і він забезпечує репрезентативний набір тематичних слів для кластера. Було показано, що кластеризація документів на основі проекції має значні переваги в ефективності. Менша кількість слів у центроїді також прискорює обчислення подібності.

У цьому розділі буде обговорено спеціалізовану варіацію $k$-середніх для тексту, яка використовує концепції з ієрархічної кластеризації. Ієрархічні методи можна легко узагальнити на текст, оскільки вони базуються на загальних поняттях подібності та відстаней. Крім того, їх поєднання з алгоритмом $k$-середніх забезпечує як стабільність, так і ефективність.

### 13.3.1.1 Підхід розсіювання/збирання

Строго кажучи, термінологія розсіювання/збирання не стосується самого алгоритму кластеризації, а можливості перегляду, яку забезпечує кластеризація. Однак у цьому розділі увага буде зосереджена на алгоритмі кластеризації. Цей алгоритм використовує комбінацію кластеризації $k$-середніх та ієрархічного розбиття. Хоча алгоритми ієрархічного розбиття дуже надійні, вони, як правило, масштабуються гірше, ніж $\Omega(n^2)$, де $n$ - кількість документів у колекції. З іншого боку, алгоритм $k$-середніх масштабується як $O(k \cdot n)$, де $k$ - кількість кластерів. Хоча алгоритм $k$-середніх більш ефективний, він іноді може бути чутливим до вибору початкових точок. Це особливо актуально для текстових даних, в яких кожен документ містить лише невелику частину лексикону. Наприклад, розглянемо випадок, коли набір документів потрібно розбити на п'ять кластерів. Звичайний алгоритм $k$-середніх вибере п'ять документів з вихідних даних як початкові точки. Кількість різних слів у цих п'яти документах, як правило, буде дуже малою підмножиною всього лексикону. Отже, перші кілька ітерацій $k$-середніх можуть не змогти присвоїти багато документів кластерам змістовно, коли вони не містять значної кількості слів із цієї малої підмножини лексикону. Ця початкова