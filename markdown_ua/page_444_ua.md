Де існують майже рівні значення якості розщеплення (дуже малі значення $\epsilon$), алгоритм повинен чекати більшого значення $n$, доки не буде задоволена зазначена вище умова розщеплення. Можна показати, що ймовірність того, що дерево Хоффдінга зробить таку ж класифікацію на прикладі, як і дерево, побудоване з нескінченними даними, становить принаймні $1 - \delta / p$, де $p$ - це ймовірність того, що приклад буде призначений до певного листа. Вимоги до пам'яті є скромними, оскільки потрібно підтримувати лише підрахунки різних дискретних значень атрибутів (за різними класами) у різних вузлах для прийняття рішень про розщеплення.
Основне теоретичне значення алгоритму дерева Хоффдінга полягає в тому, що для вирощування точно такого ж дерева, яке було б побудовано з потенційно нескінченного потоку даних, не потрібні всі дані. Натомість загальна кількість необхідних кортежів обмежена, як тільки фіксується рівень імовірнісної визначеності $\delta$. Основною вузькою стороною підходу є те, що побудова деяких вузлів затримується через майже рівні значення під час побудови дерева. Більшість часу витрачається на розв'язання майже рівних значень. В алгоритмі дерева Хоффдінга, як тільки рішення про розщеплення прийнято (і воно є поганим), його не можна скасувати. Інкрементний процес побудови дерева Хоффдінга проілюстровано на рис. 12.8. Варто зазначити, що класифікацію тестових прикладів можна виконувати в будь-який момент під час прогресування потоку, але розмір дерева збільшується з часом разом із точністю класифікації.

Підхід VFDT покращує алгоритм дерева Хоффдінга, більш агресивно розв'язуючи рівні значення та через деактивацію менш перспективних листових вузлів. Він також має низку оптимізацій для підвищення точності, таких як відкидання поганих атрибутів розщеплення та групування проміжних обчислень над кількома точками даних. Однак він не призначений для обробки дрейфу концепції. Підхід CVFDT був розроблений пізніше для вирішення проблеми дрейфу концепції. CVFDT включає дві основні ідеї для вирішення додаткових проблем дрейфу:

1. Використовується ковзне вікно навчальних елементів для обмеження впливу історичної поведінки.

2. У кожному внутрішньому вузлі $i$ будуються альтернативні піддерева для врахування того факту, що найкращий атрибут розщеплення більше не може залишатися найкращим вибором через еволюцію потоку.

Через підхід ковзного вікна відмінність від попереднього методу полягає в оновленні статистики частоти атрибутів у вузлах, оскільки ковзне вікно рухається вперед. Для вхідних елементів їхня статистика додається до частот значень атрибутів у поточному вікні, а елементи, що закінчуються на іншому кінці вікна, видаляються зі статистики. Таким чином, коли ця статистика оновлюється, деякі вузли більше не можуть задовольняти межу Хоффдінга. Такі вузли замінюються. CVFDT асоціює кожен внутрішній вузол $i$ зі списком альтернативних піддерев, що відповідають розщепленням за різними атрибутами. Ці