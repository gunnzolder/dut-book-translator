G_m і можна отримати з параметрів, оцінених на кроці M, використовуючи правило Байєса наступним чином:

$$
P(G_m | X_i) = \frac{P(G_m) \cdot P(X_i | G_m)}{\sum_{r=1}^{k} P(G_r) \cdot P(X_i | G_r)}. \tag{13.16}
$$

Таким чином, підхід PLSA також можна розглядати як метод м'якого кластерування, який надає ймовірності призначення документів до кластерів. Крім того, величина $P(w_j | G_m)$, яка оцінюється на кроці M, надає імовірнісну інформацію про імовірнісну спорідненість різних слів до аспектів (або тем). Терміни з найвищими ймовірнісними значеннями для конкретного аспекту $G_m$ можна розглядати як дайджест кластера для цієї теми.

Оскільки підхід PLSA також надає багатовимірне $n \times k$ координатне представлення $Q_k \sum_k$ документів, іншим способом виконання кластеризації було б представлення документів у цьому новому просторі та використання алгоритму k-means на перетвореному корпусі. Оскільки вплив шуму синонімії та полісемії було усунено за допомогою PLSA, підхід k-means, як правило, буде ефективнішим на зменшеному представленні, ніж на вихідному корпусі.

### 13.4.3 Обмеження PLSA

Хоча метод PLSA є інтуїтивно обґрунтованою моделлю для імовірнісного моделювання, він має низку практичних недоліків. Кількість параметрів зростає лінійно зі збільшенням кількості документів. Тому такий підхід може бути повільним і може призвести до перенавчання навчальних даних через велику кількість оцінених параметрів. Крім того, хоча PLSA надає генеративну модель пар документ-слово в навчальних даних, він не може легко призначати ймовірності раніше невідомим документам. Більшість інших моделей суміші EM, обговорених у цій книзі, таких як імовірнісна модель Байєса, набагато краще підходять для призначення ймовірностей раніше невідомим документам. Для вирішення цих проблем було визначено Латентне Розподілене Розкладання (LDA). Ця модель використовує апріорні розподіли Діріхле для тем і відносно легко узагальнюється на нові документи. У цьому сенсі LDA є повністю генеративною моделлю. У бібліографічних примітках є посилання на цю модель.

## 13.5 Спеціалізовані методи класифікації для тексту

Як і в кластеризації, на алгоритми класифікації впливає ненегативний, розріджений і високовимірний характер текстових даних. Важливим ефектом розрідженості є те, що присутність слова в документі є більш інформативною, ніж відсутність слова. Це спостереження має наслідки для методів класифікації, таких як модель Бернуллі, що використовується для класифікації Байєса, яка симетрично трактує присутність і відсутність слова.

Популярними техніками в текстовій області є методи на основі екземплярів, класифікатор Байєса та класифікатор SVM. Класифікатор Байєса дуже популярний, оскільки веб-текст часто поєднується з іншими типами ознак, такими як URL-адреси або додаткова інформація. Відносно легко включити ці ознаки в класифікатор Байєса. Розріджений високовимірний характер тексту також вимагає розробки більш вдосконалених мультиноміальних моделей Байєса для текстової області. Класифікатори SVM також надзвичайно популярні для текстових даних через їх високу точність. Основна проблема з використанням класифікатора SVM полягає в тому, що високовимірний характер тексту вимагає підвищення продуктивності таких класифікаторів. Далі буде розглянуто деякі з цих алгоритмів.